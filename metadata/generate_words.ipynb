{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Notebook to generate the words onset from the sentences\n",
    "\n",
    "First, download all the text grids, using the df that has all the sentences information (textual), and the audio files linked to each sentence.\n",
    "\n",
    "To get a textgrid, you need to input both the sentence text, and the audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary files for the API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \n",
       "0      present          9   nat_18206  \n",
       "1       future         11   nat_06950  \n",
       "2         past         11   nat_04265  \n",
       "3       future          7   nat_10108  \n",
       "4       future         12   nat_00856  \n",
       "...        ...        ...         ...  \n",
       "19195     past         10  ctrl_01195  \n",
       "19196     past          8  ctrl_01196  \n",
       "19197  present         10  ctrl_01197  \n",
       "19198  present         14  ctrl_01198  \n",
       "19199     past         13  ctrl_01199  \n",
       "\n",
       "[19200 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data_path = Path('/home/co/data/MindSentences/le_240431/241210')\n",
    "\n",
    "# dataset_file = data_path / 'final_dataset.csv'\n",
    "\n",
    "# df = pd.read_csv(dataset_file)\n",
    "\n",
    "# For 2.0 version\n",
    "sentences_path = Path('/home/co/git/MindSentences2025/versions/all_sentences/2.0/final_dataset.csv')\n",
    "df = pd.read_csv(sentences_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/nat_182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/nat_069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/nat_042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/nat_101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/nat_008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/ctrl_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/ctrl_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/ctrl_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/ctrl_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>/home/co/data/neuralset_data/audio_mp3/ctrl_01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \\\n",
       "0      present          9   nat_18206   \n",
       "1       future         11   nat_06950   \n",
       "2         past         11   nat_04265   \n",
       "3       future          7   nat_10108   \n",
       "4       future         12   nat_00856   \n",
       "...        ...        ...         ...   \n",
       "19195     past         10  ctrl_01195   \n",
       "19196     past          8  ctrl_01196   \n",
       "19197  present         10  ctrl_01197   \n",
       "19198  present         14  ctrl_01198   \n",
       "19199     past         13  ctrl_01199   \n",
       "\n",
       "                                              audio_path  \n",
       "0      /home/co/data/neuralset_data/audio_mp3/nat_182...  \n",
       "1      /home/co/data/neuralset_data/audio_mp3/nat_069...  \n",
       "2      /home/co/data/neuralset_data/audio_mp3/nat_042...  \n",
       "3      /home/co/data/neuralset_data/audio_mp3/nat_101...  \n",
       "4      /home/co/data/neuralset_data/audio_mp3/nat_008...  \n",
       "...                                                  ...  \n",
       "19195  /home/co/data/neuralset_data/audio_mp3/ctrl_01...  \n",
       "19196  /home/co/data/neuralset_data/audio_mp3/ctrl_01...  \n",
       "19197  /home/co/data/neuralset_data/audio_mp3/ctrl_01...  \n",
       "19198  /home/co/data/neuralset_data/audio_mp3/ctrl_01...  \n",
       "19199  /home/co/data/neuralset_data/audio_mp3/ctrl_01...  \n",
       "\n",
       "[19200 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First: rename all the .wav files in the audio folder into another folder called audio_mp3\n",
    "\n",
    "# audio_path = data_path / 'audio'\n",
    "audio_path = Path('/media/co/Expansion/mindsentences/audio')\n",
    "audio_mp3_path = Path('/home/co/data/neuralset_data/audio_mp3')\n",
    "audio_mp3_path.mkdir(exist_ok=True)\n",
    "\n",
    "for audio_file in audio_path.glob('*.wav'):\n",
    "    audio_file.rename(audio_mp3_path / audio_file.name.replace('.wav', '.mp3'))\n",
    "\n",
    "# Second: create a new column in the dataframe with the path to the audio file\n",
    "\n",
    "df['audio_path'] = df['audio_filename'].apply(lambda x: str(audio_mp3_path / x.replace('.wav', '_click.mp3')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>audio_path_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \\\n",
       "0      present          9   nat_18206   \n",
       "1       future         11   nat_06950   \n",
       "2         past         11   nat_04265   \n",
       "3       future          7   nat_10108   \n",
       "4       future         12   nat_00856   \n",
       "...        ...        ...         ...   \n",
       "19195     past         10  ctrl_01195   \n",
       "19196     past          8  ctrl_01196   \n",
       "19197  present         10  ctrl_01197   \n",
       "19198  present         14  ctrl_01198   \n",
       "19199     past         13  ctrl_01199   \n",
       "\n",
       "                                              audio_path  \\\n",
       "0      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "1      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "2      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "3      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "4      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "...                                                  ...   \n",
       "19195  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19196  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19197  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19198  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19199  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "\n",
       "                                        audio_path_click  \n",
       "0      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "1      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "2      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "3      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "4      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "...                                                  ...  \n",
       "19195  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19196  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19197  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19198  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19199  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "\n",
       "[19200 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for audio_file in audio_mp3_path.glob('*.mp3'):\n",
    "    # audio_file.rename(audio_mp3_path / audio_file.name.replace('_click_click.mp3', '_click.mp3'))\n",
    "\n",
    "# Second: create a new column in the dataframe with the path to the audio file\n",
    "\n",
    "df['audio_path_click'] = df['audio_path'].apply(lambda x: str(audio_mp3_path / x.replace('.mp3', '_click.mp3')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/co/Expansion/mindsentences/audio_mp3/nat_18206_click.mp3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audio_path_click'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to download all the textgrids\n",
    "\n",
    "Code to run beforehand in order to get all the textgrids using the WebMausAPI directly, instead of doing it by hand "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "\n",
    "# For each sentence, send it to MAUS and get the alignment for each word. \n",
    "# The final goal is to have a dataframe with for each sentence: its word starts and durations\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def download_textgrid(download_link):\n",
    "    try:\n",
    "        response = requests.get(download_link)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading TextGrid: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def parse_textgrid(textgrid_content):\n",
    "    intervals = []\n",
    "    interval_pattern = r'intervals \\[\\d+\\]:\\n\\s*xmin = ([0-9.]+)\\n\\s*xmax = ([0-9.]+)\\n\\s*text = \"(.*?)\"'\n",
    "    matches = re.findall(interval_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match\n",
    "        intervals.append({'start': float(start), 'end': float(end), 'text': text})\n",
    "    return intervals\n",
    "\n",
    "def test_webmaus_call(original_path, text):\n",
    "    url = \"https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/runMAUSBasic\"\n",
    "    temp_txt = Path('temp.txt')\n",
    "    temp_wav_path = None\n",
    "    files = {}\n",
    "    \n",
    "    try:\n",
    "\n",
    "        cleaned_text = text.replace(\"'\", \"'\")\n",
    "        temp_txt.write_text(cleaned_text)\n",
    "        \n",
    "        files = {\n",
    "            'SIGNAL': open(original_path, 'rb'),\n",
    "            'TEXT': open(temp_txt, 'rb')\n",
    "        }\n",
    "        \n",
    "        params = {\n",
    "            'LANGUAGE': 'eng-US',\n",
    "            'OUTFORMAT': 'TextGrid'\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, files=files, data=params, timeout=30)\n",
    "        \n",
    "        if response.content.startswith(b'<'):\n",
    "            root = ET.fromstring(response.content)\n",
    "            success = root.find('success').text\n",
    "            if success == 'false':\n",
    "                error_msg = response.content.decode()\n",
    "                raise Exception(f\"WebMAUS processing failed: {error_msg}\")\n",
    "            \n",
    "            download_link = root.find('downloadLink').text\n",
    "            if download_link:\n",
    "                return download_link\n",
    "        \n",
    "        return response.content.decode()\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        if temp_txt.exists():\n",
    "            temp_txt.unlink()\n",
    "        \n",
    "        if temp_wav_path and os.path.exists(temp_wav_path):\n",
    "            os.remove(temp_wav_path)\n",
    "        \n",
    "        for f in files.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310513415f64471ca9ab31ee2dd4fae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sentence nat_10108: WebMAUS processing failed: <WebServiceResponseLink><success>false</success><downloadLink></downloadLink><output>Could not execute the WebMAUS Basic Wrapper! Command used: &lt;br/&gt;nice -n 15 maus.pipe PIPE=G2P_MAUS SIGNAL=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_9C4FAEE764BE9CCCE9F7819DD6387305/nat_10108_click.mp3 LANGUAGE=eng-US INSKANTEXTGRID=true RELAXMINDUR=false OUTFORMAT=TextGrid PRESEG=true USETRN=false TARGETRATE=100000 TEXT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_9C4FAEE764BE9CCCE9F7819DD6387305/temp.txt INSORTTEXTGRID=true NOINITIALFINALSILENCE=false OUT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_9C4FAEE764BE9CCCE9F7819DD6387305/nat_10108_click.TextGrid  &lt;br/&gt;StdOut:  &lt;br/&gt;StdErr: ERROR: maus.pipe : mandatory TEXT input file /var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_9C4FAEE764BE9CCCE9F7819DD6387305/temp.txt not given, does not exist or has no content (empty) - exiting</output><warnings></warnings></WebServiceResponseLink>\n",
      "Error processing sentence nat_04265: WebMAUS processing failed: <WebServiceResponseLink><success>false</success><downloadLink></downloadLink><output>Could not execute the WebMAUS Basic Wrapper! Command used: &lt;br/&gt;nice -n 15 maus.pipe PIPE=G2P_MAUS SIGNAL=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_28E1CA4443760CBA3830D43A66978E2C/nat_04265_click.mp3 LANGUAGE=eng-US INSKANTEXTGRID=true RELAXMINDUR=false OUTFORMAT=TextGrid PRESEG=true USETRN=false TARGETRATE=100000 TEXT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_28E1CA4443760CBA3830D43A66978E2C/temp.txt INSORTTEXTGRID=true NOINITIALFINALSILENCE=false OUT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_28E1CA4443760CBA3830D43A66978E2C/nat_04265_click.TextGrid  &lt;br/&gt;StdOut:  &lt;br/&gt;StdErr: ERROR: maus.pipe : mandatory TEXT input file /var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_28E1CA4443760CBA3830D43A66978E2C/temp.txt not given, does not exist or has no content (empty) - exiting</output><warnings></warnings></WebServiceResponseLink>\n",
      "Error processing sentence nat_18206: WebMAUS processing failed: <WebServiceResponseLink><success>false</success><downloadLink></downloadLink><output>Could not execute the WebMAUS Basic Wrapper! Command used: &lt;br/&gt;nice -n 15 maus.pipe PIPE=G2P_MAUS SIGNAL=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_B3BF886910D78B2E95A7BB7E633D5A2B/nat_18206_click.mp3 LANGUAGE=eng-US INSKANTEXTGRID=true RELAXMINDUR=false OUTFORMAT=TextGrid PRESEG=true USETRN=false TARGETRATE=100000 TEXT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_B3BF886910D78B2E95A7BB7E633D5A2B/temp.txt INSORTTEXTGRID=true NOINITIALFINALSILENCE=false OUT=/var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_B3BF886910D78B2E95A7BB7E633D5A2B/nat_18206_click.TextGrid  &lt;br/&gt;StdOut:  &lt;br/&gt;StdErr: ERROR: maus.pipe : mandatory TEXT input file /var/lib/tomcat9/webapps/BASWebServices##4.0//data/2025.10.28_11.35.28_B3BF886910D78B2E95A7BB7E633D5A2B/temp.txt not given, does not exist or has no content (empty) - exiting</output><warnings></warnings></WebServiceResponseLink>\n",
      "Error processing sentence nat_15541: [Errno 2] No such file or directory: 'temp.txt'\n",
      "Error processing sentence nat_00856: [Errno 2] No such file or directory: 'temp.txt'\n",
      "Error processing sentence nat_13114: [Errno 2] No such file or directory: 'temp.txt'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "def process_single_sentence(row):\n",
    "    \"\"\"Process a single sentence - for parallel execution\"\"\"\n",
    "    audio_path = Path(row['audio_path'])\n",
    "    text = row['sentence']\n",
    "    sentence_id = row['sentence_id']\n",
    "    \n",
    "    try:\n",
    "        result_link = test_webmaus_call(audio_path, text)\n",
    "        if result_link:\n",
    "            textgrid_content = download_textgrid(result_link)\n",
    "            intervals = parse_textgrid(textgrid_content)\n",
    "            \n",
    "            # Save the textgrid content to a txt file\n",
    "            with open(f\"textgrid_{sentence_id}.txt\", \"w\") as f:\n",
    "                f.write(textgrid_content)\n",
    "            \n",
    "            return {\n",
    "                'sentence_id': sentence_id,\n",
    "                'intervals': intervals,\n",
    "                'status': 'success'\n",
    "            }\n",
    "    except Exception as e:\n",
    "        # Save the error message to a txt file\n",
    "        with open(f\"error_{sentence_id}.txt\", \"w\") as f:\n",
    "            f.write(str(e))\n",
    "        \n",
    "        return {\n",
    "            'sentence_id': sentence_id,\n",
    "            'intervals': None,\n",
    "            'status': 'error',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Process sentences in parallel\n",
    "results = []\n",
    "df_test = df\n",
    "# Adjust max_workers based on API rate limits (start with 5-10)\n",
    "max_workers = 10\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_single_sentence, row): row for _, row in df_test.iterrows()}\n",
    "    \n",
    "    # Process completed tasks with progress bar\n",
    "    for future in tqdm(as_completed(futures), total=len(df_test)):\n",
    "        result = future.result()\n",
    "        if result['status'] == 'success':\n",
    "            results.append({\n",
    "                'sentence_id': result['sentence_id'],\n",
    "                'intervals': result['intervals']\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Error processing sentence {result['sentence_id']}: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Create a new dataframe with the results\n",
    "df_intervals = pd.DataFrame(results)\n",
    "df_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process each sentence in the dataframe\n",
    "results = []\n",
    "\n",
    "# Test:\n",
    "df_test = df\n",
    "from tqdm.notebook import tqdm\n",
    "for index, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    audio_path = Path(row['audio_path'])\n",
    "    text = row['sentence']\n",
    "    \n",
    "    try:\n",
    "        result_link = test_webmaus_call(audio_path, text)\n",
    "        if result_link:\n",
    "            textgrid_content = download_textgrid(result_link)\n",
    "            intervals = parse_textgrid(textgrid_content)\n",
    "            results.append({\n",
    "                'sentence_id': row['sentence_id'],\n",
    "                'intervals': intervals\n",
    "            })\n",
    "            # Save the textgrid content to a txt file\n",
    "            with open(f\"textgrid_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "                f.write(textgrid_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['sentence_id']}: {str(e)}\")\n",
    "        # Save the error message to a txt file\n",
    "        with open(f\"error_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "            f.write(str(e))\n",
    "\n",
    "# Create a new dataframe with the results\n",
    "df_intervals = pd.DataFrame(results)\n",
    "df_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(\"original_textgrids\", exist_ok=True)\n",
    "os.makedirs(\"cleaned_textgrids\", exist_ok=True)\n",
    "\n",
    "# Move all existing TextGrid files to original_textgrids folder\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.txt'):\n",
    "        shutil.move(filename, os.path.join(\"original_textgrids\", filename))\n",
    "\n",
    "# Process each file in the original_textgrids folder\n",
    "for filename in os.listdir(\"original_textgrids\"):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(\"original_textgrids\", filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        # Split the content into items\n",
    "        items = content.split('item [')[1:]\n",
    "        \n",
    "        # Find the ORT-MAU item (should be the first one)\n",
    "        ort_mau = None\n",
    "        for item in items:\n",
    "            if '\"ORT-MAU\"' in item:\n",
    "                ort_mau = item\n",
    "                break\n",
    "                \n",
    "        if ort_mau:\n",
    "            # Extract all intervals\n",
    "            intervals = []\n",
    "            lines = ort_mau.split('\\n')\n",
    "            \n",
    "            # Get header information\n",
    "            header_lines = []\n",
    "            for line in content.split('\\n'):\n",
    "                if 'item [' in line:\n",
    "                    break\n",
    "                header_lines.append(line)\n",
    "                \n",
    "            # Process intervals\n",
    "            collecting_interval = False\n",
    "            current_interval = []\n",
    "            cleaned_intervals = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'intervals [' in line and not line.endswith('size'):\n",
    "                    collecting_interval = True\n",
    "                    current_interval = [line]\n",
    "                elif collecting_interval:\n",
    "                    current_interval.append(line)\n",
    "                    if 'text =' in line:\n",
    "                        text = line.split('=')[1].strip().strip('\"')\n",
    "                        if text and text != '\"\"' and not text.startswith('<'):\n",
    "                            cleaned_intervals.extend(current_interval)\n",
    "                        collecting_interval = False\n",
    "                        \n",
    "            # Create new content\n",
    "            new_content = '\\n'.join(header_lines) + '\\n'\n",
    "            new_content += 'item []:\\n    item [1]:\\n'\n",
    "            new_content += '        class = \"IntervalTier\"\\n'\n",
    "            new_content += '        name = \"ORT-MAU\"\\n'\n",
    "            new_content += f'        xmin = {content.split(\"xmin =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        xmax = {content.split(\"xmax =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        intervals: size = {len(cleaned_intervals) // 4}\\n'\n",
    "            new_content += '\\n'.join('        ' + line for line in cleaned_intervals)\n",
    "            \n",
    "            # Write the cleaned content to a new file\n",
    "            with open(os.path.join(\"cleaned_textgrids\", filename), 'w', encoding='utf-8') as file:\n",
    "                file.write(new_content)\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(content):\n",
    "    lines = content.split('\\n')\n",
    "    words = []\n",
    "    in_item_1 = False\n",
    "    current_interval = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Start capturing when we hit item [1]\n",
    "        if 'item [1]:' in line:\n",
    "            in_item_1 = True\n",
    "            continue\n",
    "        \n",
    "        # Stop capturing when we hit item [2]\n",
    "        if 'item [2]:' in line:\n",
    "            in_item_1 = False\n",
    "            break\n",
    "            \n",
    "        if in_item_1:\n",
    "            if 'intervals [' in line:\n",
    "                current_interval = {}\n",
    "            elif 'xmin =' in line:\n",
    "                current_interval['start'] = float(line.split('=')[1].strip())\n",
    "            elif 'xmax =' in line:\n",
    "                current_interval['end'] = float(line.split('=')[1].strip())\n",
    "            elif 'text =' in line:\n",
    "                text = line.split('=')[1].strip().strip('\"')\n",
    "                current_interval['text'] = text\n",
    "                words.append(current_interval)\n",
    "                current_interval = None\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame([(word['start'], word['end'], word['text']) \n",
    "                      for word in words],\n",
    "                     columns=['start', 'end', 'text'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       type                                           sentence  \\\n",
      "0  Sentence                    The kids will find joy in games   \n",
      "1      Word                    The kids will find joy in games   \n",
      "2      Word                    The kids will find joy in games   \n",
      "3      Word                    The kids will find joy in games   \n",
      "4      Word                    The kids will find joy in games   \n",
      "5      Word                    The kids will find joy in games   \n",
      "6      Word                    The kids will find joy in games   \n",
      "7      Word                    The kids will find joy in games   \n",
      "8  Sentence  Will your cousin not be at the museum with us ...   \n",
      "9      Word  Will your cousin not be at the museum with us ...   \n",
      "\n",
      "                                                text  start    end  \\\n",
      "0                    The kids will find joy in games  0.000  1.910   \n",
      "1                                                The  0.050  0.110   \n",
      "2                                               kids  0.110  0.455   \n",
      "3                                               will  0.455  0.560   \n",
      "4                                               find  0.560  0.810   \n",
      "5                                                joy  0.810  1.140   \n",
      "6                                                 in  1.140  1.260   \n",
      "7                                              games  1.260  1.910   \n",
      "8  Will your cousin not be at the museum with us ...  0.000  2.660   \n",
      "9                                               Will  0.070  0.200   \n",
      "\n",
      "   sequence_id                                         audio_path sentence_id  \n",
      "0            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "1            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "2            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "3            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "4            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "5            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "6            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "7            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "8            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n",
      "9            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_textgrid_for_words(textgrid_content):\n",
    "    # Extract word-level information from the cleaned TextGrids\n",
    "    word_pattern = r'intervals \\[\\d+\\]:\\s*xmin = ([0-9.]+)\\s*xmax = ([0-9.]+)\\s*text = \"(.*?)\"'\n",
    "    words = []\n",
    "    \n",
    "    matches = re.finditer(word_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match.groups()\n",
    "        if text.strip():  # Only include non-empty intervals\n",
    "            words.append({\n",
    "                'start': float(start),\n",
    "                'end': float(end),\n",
    "                'text': text.strip()\n",
    "            })\n",
    "    return words\n",
    "\n",
    "def create_combined_dataframe(original_df, textgrid_directory):\n",
    "    rows = []\n",
    "    \n",
    "    # First, add all sentences\n",
    "    for idx, row in original_df.iterrows():\n",
    "        # Add sentence-level entry\n",
    "        rows.append({\n",
    "            'type': 'Sentence',\n",
    "            'sentence': row['sentence'],\n",
    "            'text': row['sentence'],\n",
    "            'start': 0,\n",
    "            'end': None,  # Will be filled with the end time of the last word\n",
    "            'sequence_id': idx,\n",
    "            'audio_path': row['audio_path'],\n",
    "            'sentence_id': row['sentence_id']\n",
    "        })\n",
    "        \n",
    "        # Read and parse corresponding TextGrid file from the cleaned directory\n",
    "        textgrid_file = f\"textgrid_{row['sentence_id']}.txt\"\n",
    "        textgrid_path = Path(textgrid_directory) / 'cleaned_textgrids' / textgrid_file\n",
    "        \n",
    "        if textgrid_path.exists():\n",
    "            with open(textgrid_path, 'r', encoding='utf-8') as f:\n",
    "                textgrid_content = f.read()\n",
    "                \n",
    "            # Parse words and their timings\n",
    "            words = parse_textgrid_for_words(textgrid_content)\n",
    "            \n",
    "            # Add word-level entries\n",
    "            for word in words:\n",
    "                rows.append({\n",
    "                    'type': 'Word',\n",
    "                    'sentence': row['sentence'],\n",
    "                    'text': word['text'],\n",
    "                    'start': word['start'],\n",
    "                    'end': word['end'],\n",
    "                    'sequence_id': idx,\n",
    "                    'audio_path': row['audio_path'],\n",
    "                    'sentence_id': row['sentence_id']\n",
    "                })\n",
    "            \n",
    "            # Update the sentence end time with the last word's end time\n",
    "            if words:\n",
    "                rows[len(rows) - len(words) - 1]['end'] = words[-1]['end']\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Sort the DataFrame by sequence_id and start time\n",
    "    result_df = result_df.sort_values(['sequence_id', 'start'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Specify the directory containing the TextGrid files\n",
    "textgrid_directory = \".\"  # Replace with actual directory path if different\n",
    "\n",
    "# Create the new DataFrame\n",
    "new_df = create_combined_dataframe(df, textgrid_directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "new_df.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(new_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3280,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sequence_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>kids</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>will</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>find</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>passengers</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.510</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31042</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>quickly</td>\n",
       "      <td>3.720</td>\n",
       "      <td>4.100</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>boarded</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.490</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31044</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>the</td>\n",
       "      <td>4.490</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31045</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>train</td>\n",
       "      <td>4.550</td>\n",
       "      <td>4.970</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31046 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type                                           sentence  \\\n",
       "0      Sentence                    The kids will find joy in games   \n",
       "1          Word                    The kids will find joy in games   \n",
       "2          Word                    The kids will find joy in games   \n",
       "3          Word                    The kids will find joy in games   \n",
       "4          Word                    The kids will find joy in games   \n",
       "...         ...                                                ...   \n",
       "31041      Word  The eager child who told a story that amused t...   \n",
       "31042      Word  The eager child who told a story that amused t...   \n",
       "31043      Word  The eager child who told a story that amused t...   \n",
       "31044      Word  The eager child who told a story that amused t...   \n",
       "31045      Word  The eager child who told a story that amused t...   \n",
       "\n",
       "                                  text  start    end  sequence_id  \\\n",
       "0      The kids will find joy in games  0.000  1.910            0   \n",
       "1                                  The  0.050  0.110            0   \n",
       "2                                 kids  0.110  0.455            0   \n",
       "3                                 will  0.455  0.560            0   \n",
       "4                                 find  0.560  0.810            0   \n",
       "...                                ...    ...    ...          ...   \n",
       "31041                       passengers  2.780  3.510         3279   \n",
       "31042                          quickly  3.720  4.100         3279   \n",
       "31043                          boarded  4.100  4.490         3279   \n",
       "31044                              the  4.490  4.550         3279   \n",
       "31045                            train  4.550  4.970         3279   \n",
       "\n",
       "                                              audio_path sentence_id  \n",
       "0      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "1      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "2      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "3      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "4      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "...                                                  ...         ...  \n",
       "31041  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31042  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31043  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31044  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31045  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "\n",
       "[31046 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
