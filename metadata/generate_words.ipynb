{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Notebook to generate the words onset from the sentences\n",
    "\n",
    "First, download all the text grids, using the df that has all the sentences information (textual), and the audio files linked to each sentence.\n",
    "\n",
    "To get a textgrid, you need to input both the sentence text, and the audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary files for the API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \n",
       "0      present          9   nat_18206  \n",
       "1       future         11   nat_06950  \n",
       "2         past         11   nat_04265  \n",
       "3       future          7   nat_10108  \n",
       "4       future         12   nat_00856  \n",
       "...        ...        ...         ...  \n",
       "19195     past         10  ctrl_01195  \n",
       "19196     past          8  ctrl_01196  \n",
       "19197  present         10  ctrl_01197  \n",
       "19198  present         14  ctrl_01198  \n",
       "19199     past         13  ctrl_01199  \n",
       "\n",
       "[19200 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data_path = Path('/home/co/data/MindSentences/le_240431/241210')\n",
    "\n",
    "# dataset_file = data_path / 'final_dataset.csv'\n",
    "\n",
    "# df = pd.read_csv(dataset_file)\n",
    "\n",
    "# For 2.0 version\n",
    "sentences_path = Path('/home/co/git/MindSentences2025/versions/all_sentences/2.0/final_dataset.csv')\n",
    "df = pd.read_csv(sentences_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \\\n",
       "0      present          9   nat_18206   \n",
       "1       future         11   nat_06950   \n",
       "2         past         11   nat_04265   \n",
       "3       future          7   nat_10108   \n",
       "4       future         12   nat_00856   \n",
       "...        ...        ...         ...   \n",
       "19195     past         10  ctrl_01195   \n",
       "19196     past          8  ctrl_01196   \n",
       "19197  present         10  ctrl_01197   \n",
       "19198  present         14  ctrl_01198   \n",
       "19199     past         13  ctrl_01199   \n",
       "\n",
       "                                              audio_path  \n",
       "0      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "1      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "2      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "3      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "4      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "...                                                  ...  \n",
       "19195  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19196  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19197  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19198  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19199  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "\n",
       "[19200 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First: rename all the .wav files in the audio folder into another folder called audio_mp3\n",
    "\n",
    "# audio_path = data_path / 'audio'\n",
    "audio_path = Path('/media/co/Expansion/mindsentences/audio')\n",
    "audio_mp3_path = Path('/media/co/Expansion/mindsentences/audio_mp3')\n",
    "audio_mp3_path.mkdir(exist_ok=True)\n",
    "\n",
    "for audio_file in audio_path.glob('*.wav'):\n",
    "    audio_file.rename(audio_mp3_path / audio_file.name.replace('.wav', '.mp3'))\n",
    "\n",
    "# Second: create a new column in the dataframe with the path to the audio file\n",
    "\n",
    "df['audio_path'] = df['audio_filename'].apply(lambda x: str(audio_mp3_path / x.replace('.wav', '.mp3')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerosity</th>\n",
       "      <th>dataset</th>\n",
       "      <th>structure</th>\n",
       "      <th>theme</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>num_words</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>audio_path_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plural</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>The friends I have are not interested in sports</td>\n",
       "      <td>nat_18206.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>9</td>\n",
       "      <td>nat_18206</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>transport</td>\n",
       "      <td>Will the driver who will take me not know the ...</td>\n",
       "      <td>nat_06950.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_06950</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>independent</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The teacher was not happy when the student did...</td>\n",
       "      <td>nat_04265.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>11</td>\n",
       "      <td>nat_04265</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>simple</td>\n",
       "      <td>food</td>\n",
       "      <td>Will she not be eating breakfast tomorrow?</td>\n",
       "      <td>nat_10108.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>nat_10108</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singular</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>dependent</td>\n",
       "      <td>basic</td>\n",
       "      <td>Will the man who is not working be looking for...</td>\n",
       "      <td>nat_00856.wav</td>\n",
       "      <td>future</td>\n",
       "      <td>12</td>\n",
       "      <td>nat_00856</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>daily routine</td>\n",
       "      <td>The youthful woman who the nurse assisted ate ...</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_subject_a</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientists who studied math analyzed the i...</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>8</td>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>singular</td>\n",
       "      <td>controlled</td>\n",
       "      <td>standard_object_b</td>\n",
       "      <td>science</td>\n",
       "      <td>The scientist who the engineer assisted cautio...</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>10</td>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_d</td>\n",
       "      <td>humanity</td>\n",
       "      <td>The talented artists who viewed the designs th...</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>present</td>\n",
       "      <td>14</td>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>plural</td>\n",
       "      <td>controlled</td>\n",
       "      <td>nested_subject_c</td>\n",
       "      <td>relationship</td>\n",
       "      <td>The happy brothers who witnessed the games tha...</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>past</td>\n",
       "      <td>13</td>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "      <td>/media/co/Expansion/mindsentences/audio_mp3/ct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19200 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerosity       dataset           structure          theme  \\\n",
       "0         plural  naturalistic           dependent          basic   \n",
       "1       singular  naturalistic           dependent      transport   \n",
       "2       singular  naturalistic         independent       humanity   \n",
       "3       singular  naturalistic              simple           food   \n",
       "4       singular  naturalistic           dependent          basic   \n",
       "...          ...           ...                 ...            ...   \n",
       "19195   singular    controlled   standard_object_c  daily routine   \n",
       "19196     plural    controlled  standard_subject_a        science   \n",
       "19197   singular    controlled   standard_object_b        science   \n",
       "19198     plural    controlled    nested_subject_d       humanity   \n",
       "19199     plural    controlled    nested_subject_c   relationship   \n",
       "\n",
       "                                                sentence  audio_filename  \\\n",
       "0        The friends I have are not interested in sports   nat_18206.wav   \n",
       "1      Will the driver who will take me not know the ...   nat_06950.wav   \n",
       "2      The teacher was not happy when the student did...   nat_04265.wav   \n",
       "3             Will she not be eating breakfast tomorrow?   nat_10108.wav   \n",
       "4      Will the man who is not working be looking for...   nat_00856.wav   \n",
       "...                                                  ...             ...   \n",
       "19195  The youthful woman who the nurse assisted ate ...  ctrl_01195.wav   \n",
       "19196  The scientists who studied math analyzed the i...  ctrl_01196.wav   \n",
       "19197  The scientist who the engineer assisted cautio...  ctrl_01197.wav   \n",
       "19198  The talented artists who viewed the designs th...  ctrl_01198.wav   \n",
       "19199  The happy brothers who witnessed the games tha...  ctrl_01199.wav   \n",
       "\n",
       "         tense  num_words sentence_id  \\\n",
       "0      present          9   nat_18206   \n",
       "1       future         11   nat_06950   \n",
       "2         past         11   nat_04265   \n",
       "3       future          7   nat_10108   \n",
       "4       future         12   nat_00856   \n",
       "...        ...        ...         ...   \n",
       "19195     past         10  ctrl_01195   \n",
       "19196     past          8  ctrl_01196   \n",
       "19197  present         10  ctrl_01197   \n",
       "19198  present         14  ctrl_01198   \n",
       "19199     past         13  ctrl_01199   \n",
       "\n",
       "                                              audio_path  \\\n",
       "0      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "1      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "2      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "3      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "4      /media/co/Expansion/mindsentences/audio_mp3/na...   \n",
       "...                                                  ...   \n",
       "19195  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19196  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19197  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19198  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "19199  /media/co/Expansion/mindsentences/audio_mp3/ct...   \n",
       "\n",
       "                                        audio_path_click  \n",
       "0      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "1      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "2      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "3      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "4      /media/co/Expansion/mindsentences/audio_mp3/na...  \n",
       "...                                                  ...  \n",
       "19195  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19196  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19197  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19198  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "19199  /media/co/Expansion/mindsentences/audio_mp3/ct...  \n",
       "\n",
       "[19200 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for audio_file in audio_mp3_path.glob('*.mp3'):\n",
    "    audio_file.rename(audio_mp3_path / audio_file.name.replace('_click_click.mp3', '_click.mp3'))\n",
    "\n",
    "# Second: create a new column in the dataframe with the path to the audio file\n",
    "\n",
    "df['audio_path_click'] = df['audio_path'].apply(lambda x: str(audio_mp3_path / x.replace('.mp3', '_click.mp3')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/co/Expansion/mindsentences/audio_mp3/nat_18206_click.mp3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['audio_path_click'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to download all the textgrids\n",
    "\n",
    "Code to run beforehand in order to get all the textgrids using the WebMausAPI directly, instead of doing it by hand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6fff985f2e43919850c143d3d31a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m text = row[\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result_link = \u001b[43mtest_webmaus_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result_link:\n\u001b[32m     96\u001b[39m         textgrid_content = download_textgrid(result_link)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mtest_webmaus_call\u001b[39m\u001b[34m(original_path, text)\u001b[39m\n\u001b[32m     42\u001b[39m files = {\n\u001b[32m     43\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSIGNAL\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mopen\u001b[39m(original_path, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTEXT\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mopen\u001b[39m(temp_txt, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     45\u001b[39m }\n\u001b[32m     47\u001b[39m params = {\n\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLANGUAGE\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33meng-US\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOUTFORMAT\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mTextGrid\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     50\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.content.startswith(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     55\u001b[39m     root = ET.fromstring(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralset/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "\n",
    "# For each sentence, send it to MAUS and get the alignment for each word. \n",
    "# The final goal is to have a dataframe with for each sentence: its word starts and durations\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def download_textgrid(download_link):\n",
    "    try:\n",
    "        response = requests.get(download_link)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading TextGrid: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def parse_textgrid(textgrid_content):\n",
    "    intervals = []\n",
    "    interval_pattern = r'intervals \\[\\d+\\]:\\n\\s*xmin = ([0-9.]+)\\n\\s*xmax = ([0-9.]+)\\n\\s*text = \"(.*?)\"'\n",
    "    matches = re.findall(interval_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match\n",
    "        intervals.append({'start': float(start), 'end': float(end), 'text': text})\n",
    "    return intervals\n",
    "\n",
    "def test_webmaus_call(original_path, text):\n",
    "    url = \"https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/runMAUSBasic\"\n",
    "    temp_txt = Path('temp.txt')\n",
    "    temp_wav_path = None\n",
    "    files = {}\n",
    "    \n",
    "    try:\n",
    "\n",
    "        cleaned_text = text.replace(\"'\", \"'\")\n",
    "        temp_txt.write_text(cleaned_text)\n",
    "        \n",
    "        files = {\n",
    "            'SIGNAL': open(original_path, 'rb'),\n",
    "            'TEXT': open(temp_txt, 'rb')\n",
    "        }\n",
    "        \n",
    "        params = {\n",
    "            'LANGUAGE': 'eng-US',\n",
    "            'OUTFORMAT': 'TextGrid'\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, files=files, data=params, timeout=30)\n",
    "        \n",
    "        if response.content.startswith(b'<'):\n",
    "            root = ET.fromstring(response.content)\n",
    "            success = root.find('success').text\n",
    "            if success == 'false':\n",
    "                error_msg = response.content.decode()\n",
    "                raise Exception(f\"WebMAUS processing failed: {error_msg}\")\n",
    "            \n",
    "            download_link = root.find('downloadLink').text\n",
    "            if download_link:\n",
    "                return download_link\n",
    "        \n",
    "        return response.content.decode()\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        if temp_txt.exists():\n",
    "            temp_txt.unlink()\n",
    "        \n",
    "        if temp_wav_path and os.path.exists(temp_wav_path):\n",
    "            os.remove(temp_wav_path)\n",
    "        \n",
    "        for f in files.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Process each sentence in the dataframe\n",
    "results = []\n",
    "\n",
    "# Test:\n",
    "df_test = df\n",
    "from tqdm.notebook import tqdm\n",
    "for index, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    audio_path = Path(row['audio_path_click'])\n",
    "    text = row['sentence']\n",
    "    \n",
    "    try:\n",
    "        result_link = test_webmaus_call(audio_path, text)\n",
    "        if result_link:\n",
    "            textgrid_content = download_textgrid(result_link)\n",
    "            intervals = parse_textgrid(textgrid_content)\n",
    "            results.append({\n",
    "                'sentence_id': row['sentence_id'],\n",
    "                'intervals': intervals\n",
    "            })\n",
    "            # Save the textgrid content to a txt file\n",
    "            with open(f\"textgrid_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "                f.write(textgrid_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['sentence_id']}: {str(e)}\")\n",
    "        # Save the error message to a txt file\n",
    "        with open(f\"error_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "            f.write(str(e))\n",
    "\n",
    "# Create a new dataframe with the results\n",
    "df_intervals = pd.DataFrame(results)\n",
    "df_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(\"original_textgrids\", exist_ok=True)\n",
    "os.makedirs(\"cleaned_textgrids\", exist_ok=True)\n",
    "\n",
    "# Move all existing TextGrid files to original_textgrids folder\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.txt'):\n",
    "        shutil.move(filename, os.path.join(\"original_textgrids\", filename))\n",
    "\n",
    "# Process each file in the original_textgrids folder\n",
    "for filename in os.listdir(\"original_textgrids\"):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(\"original_textgrids\", filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        # Split the content into items\n",
    "        items = content.split('item [')[1:]\n",
    "        \n",
    "        # Find the ORT-MAU item (should be the first one)\n",
    "        ort_mau = None\n",
    "        for item in items:\n",
    "            if '\"ORT-MAU\"' in item:\n",
    "                ort_mau = item\n",
    "                break\n",
    "                \n",
    "        if ort_mau:\n",
    "            # Extract all intervals\n",
    "            intervals = []\n",
    "            lines = ort_mau.split('\\n')\n",
    "            \n",
    "            # Get header information\n",
    "            header_lines = []\n",
    "            for line in content.split('\\n'):\n",
    "                if 'item [' in line:\n",
    "                    break\n",
    "                header_lines.append(line)\n",
    "                \n",
    "            # Process intervals\n",
    "            collecting_interval = False\n",
    "            current_interval = []\n",
    "            cleaned_intervals = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'intervals [' in line and not line.endswith('size'):\n",
    "                    collecting_interval = True\n",
    "                    current_interval = [line]\n",
    "                elif collecting_interval:\n",
    "                    current_interval.append(line)\n",
    "                    if 'text =' in line:\n",
    "                        text = line.split('=')[1].strip().strip('\"')\n",
    "                        if text and text != '\"\"' and not text.startswith('<'):\n",
    "                            cleaned_intervals.extend(current_interval)\n",
    "                        collecting_interval = False\n",
    "                        \n",
    "            # Create new content\n",
    "            new_content = '\\n'.join(header_lines) + '\\n'\n",
    "            new_content += 'item []:\\n    item [1]:\\n'\n",
    "            new_content += '        class = \"IntervalTier\"\\n'\n",
    "            new_content += '        name = \"ORT-MAU\"\\n'\n",
    "            new_content += f'        xmin = {content.split(\"xmin =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        xmax = {content.split(\"xmax =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        intervals: size = {len(cleaned_intervals) // 4}\\n'\n",
    "            new_content += '\\n'.join('        ' + line for line in cleaned_intervals)\n",
    "            \n",
    "            # Write the cleaned content to a new file\n",
    "            with open(os.path.join(\"cleaned_textgrids\", filename), 'w', encoding='utf-8') as file:\n",
    "                file.write(new_content)\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(content):\n",
    "    lines = content.split('\\n')\n",
    "    words = []\n",
    "    in_item_1 = False\n",
    "    current_interval = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Start capturing when we hit item [1]\n",
    "        if 'item [1]:' in line:\n",
    "            in_item_1 = True\n",
    "            continue\n",
    "        \n",
    "        # Stop capturing when we hit item [2]\n",
    "        if 'item [2]:' in line:\n",
    "            in_item_1 = False\n",
    "            break\n",
    "            \n",
    "        if in_item_1:\n",
    "            if 'intervals [' in line:\n",
    "                current_interval = {}\n",
    "            elif 'xmin =' in line:\n",
    "                current_interval['start'] = float(line.split('=')[1].strip())\n",
    "            elif 'xmax =' in line:\n",
    "                current_interval['end'] = float(line.split('=')[1].strip())\n",
    "            elif 'text =' in line:\n",
    "                text = line.split('=')[1].strip().strip('\"')\n",
    "                current_interval['text'] = text\n",
    "                words.append(current_interval)\n",
    "                current_interval = None\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame([(word['start'], word['end'], word['text']) \n",
    "                      for word in words],\n",
    "                     columns=['start', 'end', 'text'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       type                                           sentence  \\\n",
      "0  Sentence                    The kids will find joy in games   \n",
      "1      Word                    The kids will find joy in games   \n",
      "2      Word                    The kids will find joy in games   \n",
      "3      Word                    The kids will find joy in games   \n",
      "4      Word                    The kids will find joy in games   \n",
      "5      Word                    The kids will find joy in games   \n",
      "6      Word                    The kids will find joy in games   \n",
      "7      Word                    The kids will find joy in games   \n",
      "8  Sentence  Will your cousin not be at the museum with us ...   \n",
      "9      Word  Will your cousin not be at the museum with us ...   \n",
      "\n",
      "                                                text  start    end  \\\n",
      "0                    The kids will find joy in games  0.000  1.910   \n",
      "1                                                The  0.050  0.110   \n",
      "2                                               kids  0.110  0.455   \n",
      "3                                               will  0.455  0.560   \n",
      "4                                               find  0.560  0.810   \n",
      "5                                                joy  0.810  1.140   \n",
      "6                                                 in  1.140  1.260   \n",
      "7                                              games  1.260  1.910   \n",
      "8  Will your cousin not be at the museum with us ...  0.000  2.660   \n",
      "9                                               Will  0.070  0.200   \n",
      "\n",
      "   sequence_id                                         audio_path sentence_id  \n",
      "0            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "1            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "2            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "3            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "4            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "5            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "6            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "7            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "8            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n",
      "9            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_textgrid_for_words(textgrid_content):\n",
    "    # Extract word-level information from the cleaned TextGrids\n",
    "    word_pattern = r'intervals \\[\\d+\\]:\\s*xmin = ([0-9.]+)\\s*xmax = ([0-9.]+)\\s*text = \"(.*?)\"'\n",
    "    words = []\n",
    "    \n",
    "    matches = re.finditer(word_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match.groups()\n",
    "        if text.strip():  # Only include non-empty intervals\n",
    "            words.append({\n",
    "                'start': float(start),\n",
    "                'end': float(end),\n",
    "                'text': text.strip()\n",
    "            })\n",
    "    return words\n",
    "\n",
    "def create_combined_dataframe(original_df, textgrid_directory):\n",
    "    rows = []\n",
    "    \n",
    "    # First, add all sentences\n",
    "    for idx, row in original_df.iterrows():\n",
    "        # Add sentence-level entry\n",
    "        rows.append({\n",
    "            'type': 'Sentence',\n",
    "            'sentence': row['sentence'],\n",
    "            'text': row['sentence'],\n",
    "            'start': 0,\n",
    "            'end': None,  # Will be filled with the end time of the last word\n",
    "            'sequence_id': idx,\n",
    "            'audio_path': row['audio_path'],\n",
    "            'sentence_id': row['sentence_id']\n",
    "        })\n",
    "        \n",
    "        # Read and parse corresponding TextGrid file from the cleaned directory\n",
    "        textgrid_file = f\"textgrid_{row['sentence_id']}.txt\"\n",
    "        textgrid_path = Path(textgrid_directory) / 'cleaned_textgrids' / textgrid_file\n",
    "        \n",
    "        if textgrid_path.exists():\n",
    "            with open(textgrid_path, 'r', encoding='utf-8') as f:\n",
    "                textgrid_content = f.read()\n",
    "                \n",
    "            # Parse words and their timings\n",
    "            words = parse_textgrid_for_words(textgrid_content)\n",
    "            \n",
    "            # Add word-level entries\n",
    "            for word in words:\n",
    "                rows.append({\n",
    "                    'type': 'Word',\n",
    "                    'sentence': row['sentence'],\n",
    "                    'text': word['text'],\n",
    "                    'start': word['start'],\n",
    "                    'end': word['end'],\n",
    "                    'sequence_id': idx,\n",
    "                    'audio_path': row['audio_path'],\n",
    "                    'sentence_id': row['sentence_id']\n",
    "                })\n",
    "            \n",
    "            # Update the sentence end time with the last word's end time\n",
    "            if words:\n",
    "                rows[len(rows) - len(words) - 1]['end'] = words[-1]['end']\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Sort the DataFrame by sequence_id and start time\n",
    "    result_df = result_df.sort_values(['sequence_id', 'start'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Specify the directory containing the TextGrid files\n",
    "textgrid_directory = \".\"  # Replace with actual directory path if different\n",
    "\n",
    "# Create the new DataFrame\n",
    "new_df = create_combined_dataframe(df, textgrid_directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "new_df.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(new_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3280,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sequence_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>kids</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>will</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>find</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>passengers</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.510</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31042</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>quickly</td>\n",
       "      <td>3.720</td>\n",
       "      <td>4.100</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>boarded</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.490</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31044</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>the</td>\n",
       "      <td>4.490</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31045</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>train</td>\n",
       "      <td>4.550</td>\n",
       "      <td>4.970</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31046 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type                                           sentence  \\\n",
       "0      Sentence                    The kids will find joy in games   \n",
       "1          Word                    The kids will find joy in games   \n",
       "2          Word                    The kids will find joy in games   \n",
       "3          Word                    The kids will find joy in games   \n",
       "4          Word                    The kids will find joy in games   \n",
       "...         ...                                                ...   \n",
       "31041      Word  The eager child who told a story that amused t...   \n",
       "31042      Word  The eager child who told a story that amused t...   \n",
       "31043      Word  The eager child who told a story that amused t...   \n",
       "31044      Word  The eager child who told a story that amused t...   \n",
       "31045      Word  The eager child who told a story that amused t...   \n",
       "\n",
       "                                  text  start    end  sequence_id  \\\n",
       "0      The kids will find joy in games  0.000  1.910            0   \n",
       "1                                  The  0.050  0.110            0   \n",
       "2                                 kids  0.110  0.455            0   \n",
       "3                                 will  0.455  0.560            0   \n",
       "4                                 find  0.560  0.810            0   \n",
       "...                                ...    ...    ...          ...   \n",
       "31041                       passengers  2.780  3.510         3279   \n",
       "31042                          quickly  3.720  4.100         3279   \n",
       "31043                          boarded  4.100  4.490         3279   \n",
       "31044                              the  4.490  4.550         3279   \n",
       "31045                            train  4.550  4.970         3279   \n",
       "\n",
       "                                              audio_path sentence_id  \n",
       "0      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "1      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "2      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "3      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "4      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "...                                                  ...         ...  \n",
       "31041  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31042  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31043  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31044  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31045  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "\n",
       "[31046 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
